{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b332ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df0126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a reference to the \"hacker_news\" dataset\n",
    "dataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac0a769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all the tables in the \"hacker_news\" dataset\n",
    "tables = list(client.list_tables(dataset))\n",
    "\n",
    "# Print names of all tables in the dataset (there are four!)\n",
    "for table in tables:  \n",
    "    print(table.table_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eb6f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a reference to the \"full\" table\n",
    "table_ref = dataset_ref.table(\"full\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa21ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print information on all the columns in the \"full\" table in the \"hacker_news\" dataset\n",
    "table.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c43551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the first five lines of the \"full\" table\n",
    "client.list_rows(table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3e9f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the first five entries in the \"by\" column of the \"full\" table\n",
    "client.list_rows(table, selected_fields=table.schema[:1], max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef350bd7",
   "metadata": {},
   "source": [
    "exercise 2, 1 table, get access to crime dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc488f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a reference to the \"crime\" table\n",
    "table_ref = dataset_ref.table(\"crime\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "# Print information on all the columns in the \"crime\" table in the \"chicago_crime\" dataset\n",
    "print(table.schema)\n",
    "\n",
    "num_timestamp_fields = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84642a67",
   "metadata": {},
   "source": [
    "global air \n",
    "US , global_air_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f898491a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Set up the query\n",
    "query_job = client.query(query)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "us_cities = query_job.to_dataframe()\n",
    "\n",
    "# What five cities have the most measurements?\n",
    "us_cities.city.value_counts().head()\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT city, country\n",
    "        FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "        WHERE country = 'US'\n",
    "        \"\"\"\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "        WHERE country = 'US'\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945aa719",
   "metadata": {},
   "source": [
    "very big datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24a1b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to get the score column from every row where the type column has value \"job\"\n",
    "query = \"\"\"\n",
    "        SELECT score, title\n",
    "        FROM `bigquery-public-data.hacker_news.full`\n",
    "        WHERE type = \"job\" \n",
    "        \"\"\"\n",
    "\n",
    "# Create a QueryJobConfig object to estimate size of query without running it\n",
    "dry_run_config = bigquery.QueryJobConfig(dry_run=True)\n",
    "\n",
    "# API request - dry run query to estimate costs\n",
    "dry_run_query_job = client.query(query, job_config=dry_run_config)\n",
    "\n",
    "print(\"This query will process {} bytes.\".format(dry_run_query_job.total_bytes_processed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233cd4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run the query if it's less than 1 MB\n",
    "ONE_MB = 1000*1000\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=ONE_MB)\n",
    "\n",
    "# Set up the query (will only run if it's less than 1 MB)\n",
    "safe_query_job = client.query(query, job_config=safe_config)\n",
    "\n",
    "# API request - try to run the query, and return a pandas DataFrame\n",
    "safe_query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6af337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run the query if it's less than 1 GB\n",
    "ONE_GB = 1000*1000*1000\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=ONE_GB)\n",
    "\n",
    "# Set up the query (will only run if it's less than 1 GB)\n",
    "safe_query_job = client.query(query, job_config=safe_config)\n",
    "\n",
    "# API request - try to run the query, and return a pandas DataFrame\n",
    "job_post_scores = safe_query_job.to_dataframe()\n",
    "\n",
    "# Print average score for job posts\n",
    "job_post_scores.score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af03b97",
   "metadata": {},
   "source": [
    "--- exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e52a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up feedback system\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.sql.ex2 import *\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdf0e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Construct a reference to the \"openaq\" dataset\n",
    "dataset_ref = client.dataset(\"openaq\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)\n",
    "\n",
    "# Construct a reference to the \"global_air_quality\" table\n",
    "table_ref = dataset_ref.table(\"global_air_quality\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "# Preview the first five lines of the \"global_air_quality\" table\n",
    "client.list_rows(table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa895ed2",
   "metadata": {},
   "source": [
    "unit= ppm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0201c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to select countries with units of \"ppm\"\n",
    "first_query = \"\"\"\n",
    "        SELECT country\n",
    "        FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "        WHERE unit = \"ppm\" \n",
    "        \"\"\" # Your code goes here\n",
    "\n",
    "# Set up the query (cancel the query if it would use too much of \n",
    "# your quota, with the limit set to 10 GB)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "first_query_job = client.query(first_query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "first_results = first_query_job.to_dataframe()\n",
    "\n",
    "# View top few rows of results\n",
    "print(first_results.head())\n",
    "\n",
    "# Check your answer\n",
    "q_1.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e77c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to select all columns where pollution levels are exactly 0\n",
    "zero_pollution_query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "        WHERE value = 0 # Your code goes here\"\"\"\n",
    "\n",
    "# Set up the query\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "query_job = client.query(zero_pollution_query, job_config=safe_config)\n",
    "\n",
    "\n",
    "# API request - run the query and return a pandas DataFrame\n",
    "zero_pollution_results = query_job.to_dataframe() # Your code goes here\n",
    "\n",
    "print(zero_pollution_results.head())\n",
    "\n",
    "# Check your answer\n",
    "q_2.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d93dc88",
   "metadata": {},
   "source": [
    "comments - group by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5ae7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to select comments that received more than 10 replies\n",
    "query_popular = \"\"\"\n",
    "                SELECT parent, COUNT(id)\n",
    "                FROM `bigquery-public-data.hacker_news.comments`\n",
    "                GROUP BY parent\n",
    "                HAVING COUNT(id) > 10\n",
    "                \"\"\"\n",
    "\n",
    "# Set up the query (cancel the query if it would use too much of \n",
    "# your quota, with the limit set to 10 GB)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "query_job = client.query(query_popular, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and convert the results to a pandas DataFrame\n",
    "popular_comments = query_job.to_dataframe()\n",
    "\n",
    "# Print the first five rows of the DataFrame\n",
    "popular_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14a5b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved version of earlier query, now with aliasing & improved readability\n",
    "query_improved = \"\"\"\n",
    "                 SELECT parent, COUNT(1) AS NumPosts\n",
    "                 FROM `bigquery-public-data.hacker_news.comments`\n",
    "                 GROUP BY parent\n",
    "                 HAVING COUNT(1) > 10\n",
    "                 \"\"\"\n",
    "\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "query_job = client.query(query_improved, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and convert the results to a pandas DataFrame\n",
    "improved_df = query_job.to_dataframe()\n",
    "\n",
    "# Print the first five rows of the DataFrame\n",
    "improved_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b73a1e6",
   "metadata": {},
   "source": [
    "Note that there are two variables: parent and id.\n",
    "\n",
    "parent was passed to a GROUP BY command (in GROUP BY parent), and\n",
    "id was passed to an aggregate function (in COUNT(id))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa0733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_bad = \"\"\"\n",
    "            SELECT author, parent, COUNT(id)\n",
    "            FROM `bigquery-public-data.hacker_news.comments`\n",
    "            GROUP BY parent\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ba2b3f",
   "metadata": {},
   "source": [
    "exercise 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a4f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up feedback system\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.sql.ex3 import *\n",
    "print(\"Setup Complete\")\n",
    "\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Construct a reference to the \"hacker_news\" dataset\n",
    "dataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)\n",
    "\n",
    "# Construct a reference to the \"comments\" table\n",
    "table_ref = dataset_ref.table(\"comments\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "# Preview the first five lines of the \"comments\" table\n",
    "client.list_rows(table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc76aca2",
   "metadata": {},
   "source": [
    "posts 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0362a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to select prolific commenters and post counts\n",
    "prolific_commenters_query = \"\"\"\n",
    "        SELECT author, COUNT(1) AS NumPosts\n",
    "        FROM `bigquery-public-data.hacker_news.comments`\n",
    "        GROUP BY author\n",
    "        HAVING COUNT(1) > 10000\n",
    "        \"\"\" # Your code goes here\n",
    "\n",
    "# Set up the query (cancel the query if it would use too much of \n",
    "# your quota, with the limit set to 1 GB)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "query_job = client.query(prolific_commenters_query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "prolific_commenters = query_job.to_dataframe()\n",
    "\n",
    "# View top few rows of results\n",
    "print(prolific_commenters.head())\n",
    "\n",
    "# Check your answer\n",
    "q_1.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa52060",
   "metadata": {},
   "source": [
    "check deleted column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566d7ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your query here and figure out the answer\n",
    "query = \"\"\"\n",
    "                      SELECT COUNT(1) AS num_deleted_posts\n",
    "                      FROM `bigquery-public-data.hacker_news.comments`\n",
    "                      WHERE deleted = True\n",
    "                      \"\"\"\n",
    "# Your code goes here\n",
    "\n",
    "# Set up the query (cancel the query if it would use too much of \n",
    "# your quota, with the limit set to 1 GB)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "query_job = client.query(query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "deleted = query_job.to_dataframe()\n",
    "\n",
    "# View top few rows of results\n",
    "print(deleted.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc6f34d",
   "metadata": {},
   "source": [
    "exract- order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cc4125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to find out the number of accidents for each day of the week\n",
    "query = \"\"\"\n",
    "        SELECT COUNT(consecutive_number) AS num_accidents, \n",
    "               EXTRACT(DAYOFWEEK FROM timestamp_of_crash) AS day_of_week\n",
    "        FROM `bigquery-public-data.nhtsa_traffic_fatalities.accident_2015`\n",
    "        GROUP BY day_of_week\n",
    "        ORDER BY num_accidents DESC\n",
    "        \"\"\"\n",
    "\n",
    "# Set up the query (cancel the query if it would use too much of \n",
    "# your quota, with the limit set to 1 GB)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**9)\n",
    "query_job = client.query(query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and convert the results to a pandas DataFrame\n",
    "accidents_by_day = query_job.to_dataframe()\n",
    "\n",
    "# Print the DataFrame\n",
    "accidents_by_day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0d4540",
   "metadata": {},
   "source": [
    "world_bank_intl_education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f07b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Construct a reference to the \"world_bank_intl_education\" dataset\n",
    "dataset_ref = client.dataset(\"world_bank_intl_education\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)\n",
    "\n",
    "# Construct a reference to the \"international_education\" table\n",
    "table_ref = dataset_ref.table(\"international_education\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "# Preview the first five lines of the \"international_education\" table\n",
    "client.list_rows(table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50c7cae",
   "metadata": {},
   "source": [
    "To answer this question, consider only the rows in the dataset corresponding to indicator code SE.XPD.TOTL.GD.ZS, and write a query that returns the average value in the value column for each country in the dataset between the years 2010-2017 (including 2010 and 2017 in the average).\n",
    "\n",
    "Requirements:\n",
    "\n",
    "Your results should have the country name rather than the country code. You will have one row for each country.\n",
    "The aggregate function for average is AVG(). Use the name avg_ed_spending_pct for the column created by this aggregation.\n",
    "Order the results so the countries that spend the largest fraction of GDP on education show up first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35451050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "country_spend_pct_query = \"\"\"\n",
    "                          SELECT country_name, AVG(value) as avg_ed_spending_pct\n",
    "                          FROM `bigquery-public-data.world_bank_intl_education.international_education`\n",
    "                          WHERE indicator_code= \"SE.XPD.TOTL.GD.ZS\" and year >= 2010 and year <= 2017\n",
    "                          GROUP BY country_name\n",
    "                          ORDER BY avg_ed_spending_pct DESC\n",
    "                          \"\"\"\n",
    "\n",
    "# Set up the query (cancel the query if it would use too much of \n",
    "# your quota, with the limit set to 1 GB)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "country_spend_pct_query_job = client.query(country_spend_pct_query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "country_spending_results = country_spend_pct_query_job.to_dataframe()\n",
    "\n",
    "# View top few rows of results\n",
    "print(country_spending_results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d00a64e",
   "metadata": {},
   "source": [
    " Identify interesting codes to explore¶\n",
    "The last question started by telling you to focus on rows with the code SE.XPD.TOTL.GD.ZS. But how would you find more interesting indicator codes to explore?\n",
    "\n",
    "There are 1000s of codes in the dataset, so it would be time consuming to review them all. But many codes are available for only a few countries. When browsing the options for different codes, you might restrict yourself to codes that are reported by many countries.\n",
    "\n",
    "Write a query below that selects the indicator code and indicator name for all codes with at least 175 rows in the year 2016.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "You should have one row for each indicator code.\n",
    "The columns in your results should be called indicator_code, indicator_name, and num_rows.\n",
    "Only select codes with 175 or more rows in the raw database (exactly 175 rows would be included).\n",
    "To get both the indicator_code and indicator_name in your resulting DataFrame, you need to include both in your SELECT statement (in addition to a COUNT() aggregation). This requires you to include both in your GROUP BY clause.\n",
    "Order from results most frequent to least frequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfb9838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "code_count_query = \"\"\"\n",
    "                   SELECT indicator_code, indicator_name, COUNT(1) AS num_rows\n",
    "                   FROM `bigquery-public-data.world_bank_intl_education.international_education`\n",
    "                   WHERE year = 2016\n",
    "                   GROUP BY indicator_name, indicator_code\n",
    "                   HAVING COUNT(1) >= 175\n",
    "                   ORDER BY COUNT(1) DESC\n",
    "                   \"\"\"\n",
    "\n",
    "\n",
    "# Set up the query\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "code_count_query_job = client.query(code_count_query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "code_count_results = code_count_query_job.to_dataframe()\n",
    "\n",
    "# View top few rows of results\n",
    "print(code_count_results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7549a6e0",
   "metadata": {},
   "source": [
    "transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171a56f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to select the number of transactions per date, sorted by date\n",
    "query_with_CTE = \"\"\" \n",
    "                 WITH time AS \n",
    "                 (\n",
    "                     SELECT DATE(block_timestamp) AS trans_date\n",
    "                     FROM `bigquery-public-data.crypto_bitcoin.transactions`\n",
    "                 )\n",
    "                 SELECT COUNT(1) AS transactions,\n",
    "                        trans_date\n",
    "                 FROM time\n",
    "                 GROUP BY trans_date\n",
    "                 ORDER BY trans_date\n",
    "                 \"\"\"\n",
    "\n",
    "# Set up the query (cancel the query if it would use too much of \n",
    "# your quota, with the limit set to 10 GB)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "query_job = client.query(query_with_CTE, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and convert the results to a pandas DataFrame\n",
    "transactions_by_date = query_job.to_dataframe()\n",
    "\n",
    "# Print the first five rows\n",
    "transactions_by_date.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827af0f9",
   "metadata": {},
   "source": [
    "Since they're returned sorted, we can easily plot the raw results to show us the number of Bitcoin transactions per day over the whole timespan of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685246da",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_by_date.set_index('trans_date').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958d72d4",
   "metadata": {},
   "source": [
    "exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5c046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up feedback system\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.sql.ex5 import *\n",
    "print(\"Setup Complete\")\n",
    "\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Construct a reference to the \"chicago_taxi_trips\" dataset\n",
    "dataset_ref = client.dataset(\"chicago_taxi_trips\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9297926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all the tables in the dataset\n",
    "tables = list(client.list_tables(dataset))\n",
    "\n",
    "# Print names of all tables in the dataset (there is only one!)\n",
    "for table in tables:  \n",
    "    print(table.table_id)\n",
    "    \n",
    "table_name = 'taxi_trips'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec17e775",
   "metadata": {},
   "source": [
    "3) Determine when this data is from¶\n",
    "If the data is sufficiently old, we might be careful before assuming the data is still relevant to traffic patterns today. Write a query that counts the number of trips in each year.\n",
    "\n",
    "Your results should have two columns:\n",
    "\n",
    "year - the year of the trips\n",
    "num_trips - the number of trips in that year\n",
    "Hints:\n",
    "\n",
    "When using GROUP BY and ORDER BY, you should refer to the columns by the alias year that you set at the top of the SELECT query.\n",
    "The SQL code to SELECT the year from trip_start_timestamp is SELECT EXTRACT(YEAR FROM trip_start_timestamp)\n",
    "The FROM field can be a little tricky until you are used to it. The format is:\n",
    "A backick (the symbol `).\n",
    "The project name. In this case it is bigquery-public-data.\n",
    "A period.\n",
    "The dataset name. In this case, it is chicago_taxi_trips.\n",
    "A period.\n",
    "The table name. You used this as your answer in 1) Find the data.\n",
    "A backtick (the symbol `)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5706e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "rides_per_year_query = \"\"\"\n",
    "                       SELECT EXTRACT(YEAR FROM trip_start_timestamp) AS year, \n",
    "                              COUNT(1) AS num_trips\n",
    "                       FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "                       GROUP BY year\n",
    "                       ORDER BY year\n",
    "                       \"\"\"\n",
    "\n",
    "# Set up the query (cancel the query if it would use too much of \n",
    "# your quota)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "rides_per_year_query_job =client.query(rides_per_year_query, job_config=safe_config)\n",
    " # Your code goes here\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "rides_per_year_result = rides_per_year_query_job.to_dataframe() # Your code goes here\n",
    "\n",
    "# View results\n",
    "print(rides_per_year_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
